---
title: "p8105_hw5_lmp2234"
author: "Lisa Pardee"
date: "2024-11-13"
output: github_document
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom)
library(dplyr)
knitr::opts_chunk$set(
  echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
  
theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1. 

```{r}

birthday_sim <- function(n) {
  birthday <- sample(1:365, n, replace = TRUE)
  return(anyDuplicated(birthday)>0)
}

set.seed(42)
group_sizes <- 2:50
probabilities <- numeric(length(group_sizes))

for (i in group_sizes){
  simulations <- replicate(10000, birthday_sim(i))
  probabilities[i-1] <- mean(simulations)
}

data <- data.frame(group_size = group_sizes, probability = probabilities)


ggplot(data, aes(x = group_size, y = probability)) +
  geom_line() + 
  geom_point() + 
  labs(
    x = "Group Size",
    y = "Probability of Shared Birthday",
    title = "Probability of At Least Two People Sharing a Birthday"
  ) +
  theme_minimal()

```
The plot shows that as group size increases, the probability of two people sharing the same birthday increases as well. 


## Problem 2
# Setting the following design elements  

```{r}
n <- 30
sigma <- 5
mu_values <-c(0,1,2,3,4,5,6)
n_sims <-5000 

sim_ttest <- function(mu = 0) {
  data <-  tibble(x = rnorm(n, mean = mu, sd = sigma))
  ttest <- t.test(x~1, data = data)
  tidy(ttest) %>%
    select(estimate, p.value) %>%
    mutate(mu = mu)
}

```

# Running a simulation of ttest for each value of mu and inserting into data frame 

```{r}
results <- map(mu_values , function(mu) {
  replicate(n_sims, sim_ttest(mu), simplify = FALSE)
})

results <- lapply(results, as.data.frame)
```

# Creating a column indicating if null hypothesis is rejected if p-value is <0.05 
```{r}
results_df <- results %>%
  map_dfr(~ .x, .id = "mu") %>%
  mutate(mu = as.numeric(mu), 
         rejected = p.value < 0.05)
```

# Calculating the statistical power for each mu 
```{r}
df_power <- results_df %>%
  group_by(mu) %>%
  summarize(power = mean(rejected,na.rm = TRUE), .groups = "drop" )
```


# Plot of the Proportion of Times Null was Rejected 
```{r}
ggplot(df_power, aes(x = mu, y = power))+
  geom_point () + 
  geom_line()+
  labs(x= "Mu", y = "Power")
```
The association between effect size and power is that as the effect size increases, the statistical power of the test increases as well. However, the power cannot exceed 1 since the range goes from 0 to 1, as displayed by the graph. As the effect size increases, the largest power it can reach is 1. 

# Plot of Average Estimates of ùúáÃÇ and the trueùúá
 
```{r}

estimate_cols <- grep("estimate", names(results_df), value = TRUE)
pvalue_cols <- grep("p.value", names(results_df), value = TRUE)

long_data <- list()

for (i in 1:length(estimate_cols)) {

   estimate_data <- results_df[[estimate_cols[i]]]
   pvalue_data <- results_df[[pvalue_cols[i]]]
  
   temp_data <- tibble(
     estimate = estimate_data,
     p.value = pvalue_data,
     mu = results_df[[paste0("mu.", i)]]  
   )
   
   long_data[[i]] <- temp_data
}

results_long <- bind_rows(long_data)
head(results_long)

```

```{r}
ggplot(
  bind_rows(
    results_long %>%
      group_by(mu) %>%
      summarize(avg_estimate = mean(estimate, na.rm = TRUE), .groups = "drop") %>%
      mutate(type = "All Samples"),
    
    results_long %>%
      filter(p.value < 0.05) %>%
      group_by(mu) %>%
      summarize(avg_estimate = mean(estimate, na.rm = TRUE), .groups = "drop") %>%
      mutate(type = "Rejected Nulls")
  ),
  aes(x = mu, y = avg_estimate, color = type)
) +
 geom_point() + 
  geom_line() +
  labs(x = "True Mean (Mu)", y = "Average Estimate of Mu (MuÃÇ)", 
       title = "Average Estimate of Mu vs True Mu") +
  theme_minimal()

```
The average of ùúáÃÇacross all tests for which the null is rejected is not always approximately equal to the true value of ùúá. The distribution of sample means may be skewed when you reject the null hypothesis since rejecting the null means only including sample means different from the null hypothesis (i.e., thus biasing). 

## Problem 3 

```{r}
homocide_df = read.csv(
  "data/homicide-data.csv")

head(homocide_df)

```

# Data Description 
The dataset contains observations on `r nrow(homocide_df)` criminal homocides over the past decade in 50 of the largest American cities. The data include `r ncol(homocide_df)` variables, and are primarily demographic characteristics about the victims, the location of the killings, and whether an arrest was made. 

# Creating city_state variable and summarizing within cities 
```{r}
homocide_df <- homocide_df %>%
  mutate(city_state = paste(city, state, sep = ","))
  

summarize_homocide <- homocide_df %>%
  group_by(city_state)  %>%
  summarize(
    total_homocides = n(), 
    unsolved_homocides = sum(disposition %in% c("Closed without arrest", "Open/No arrest")), 
    .groups = "drop"
  )

print(summarize_homocide)
```


# Using prop test to estimate proportion of homocides that are unsolved in Baltimore, MD.

```{r}
baltimore_df <- summarize_homocide  %>%
  filter(city_state == "Baltimore,MD")

prop_testdf <- prop.test(
  baltimore_df[["unsolved_homocides"]],
  baltimore_df[["total_homocides"]]
)

tidy_result <- tidy(prop_testdf)

estimate_proportion <- tidy_result [["estimate"]]
lower_ci <- tidy_result[["conf.low"]]
upper_ci <- tidy_result[["conf.high"]]

cat("Estimated Proportion of Unsolved Homocides", estimate_proportion, "\n")
cat("Confidence Interval: [", lower_ci, ",", upper_ci, "]\n")


```

# Creating the table that lists estimates and confidence intervals per city 
```{r}

prop_df <- summarize_homocide  %>%
  mutate(prop_test = pmap(
    list(unsolved_homocides = summarize_homocide[["unsolved_homocides"]], 
         total_homocides = summarize_homocide[["total_homocides"]]), 
    ~ prop.test(..1, ..2)
  )) %>%
  mutate(tidy_results = map(prop_test, tidy)) %>%
  unnest(tidy_results) %>%
  select(city_state, estimate, conf.low, conf.high)
      
print(prop_df)
```
# Creating a Plot of Estimates & CIs for Each City 

```{r}
prop_df  %>%
  mutate(city_state = reorder(city_state, estimate))  %>%
  ggplot(aes(x=estimate, y=city_state))+
  geom_point(size = 3) +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0.1)+
  labs(
    x = "Proportion of Unsolved Homocides", 
    y = "City", 
    title = "Proportion of Unsolved Homocides by City with 95% CIs"
  )+
  theme_minimal()+
  theme(
    axis.text.y = element_text(size = 7),
    axis.text.x = element_text(size = 10),
    plot.margin = margin(1, 1, 1, 3, "cm")
  )
```


